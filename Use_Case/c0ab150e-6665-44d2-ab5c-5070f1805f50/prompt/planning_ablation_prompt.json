{
  "stage": "planning_ablation",
  "timestamp": "2026-01-17T06:34:10.804778+00:00",
  "request": {
    "messages": [
      {
        "role": "system",
        "content": "You are an expert academic paper figure analysis assistant. Your task is to read\nthe LaTeX snippet of an experiment or ablation section and decide which figures\nshould be created, then return detailed, structured information for each figure.\n\nRequirements:\n1. Carefully read the LaTeX snippet (experiment or ablation part).\n2. Identify all content that should be visualized: metrics, comparisons, ablations, **tables, and existing figure environments** (even if a table/figure is already present, you should still propose a corresponding visualization for our automatic pipeline).\n3. For each figure that should be created, generate:\n   - filename: a descriptive English file name, e.g. \"performance_comparison.png\"\n   - description: a **detailed** description of what the figure shows\n   - old_string: a text span from the LaTeX snippet near where the figure should be inserted\n   - new_string: the replacement text that includes the LaTeX code for inserting the figure\n\nGuidelines:\n1. **Figure diversity is crucial**: You should propose a **variety of figure types** based on the data characteristics:\n   - **Bar charts**: for comparing discrete categories (methods, datasets, components)\n   - **Line plots**: for showing trends over continuous variables (epochs, learning rates, time)\n   - **Scatter plots**: for correlation analysis or distribution visualization\n   - **Heatmaps**: for matrix data (confusion matrices, correlation matrices, parameter grids)\n   - **Box plots**: for statistical distributions and comparisons\n   - **Violin plots**: for detailed distribution shapes\n   - **Multi-panel/subplot figures**: for combining related visualizations\n   - **3D plots**: for three-dimensional data relationships\n   - **Pie charts**: for proportional comparisons (use sparingly)\n   - **Error bar plots**: for showing uncertainty/confidence intervals\n   - Choose the most appropriate visualization type for each data pattern.\n\n2. **Experiment sections** usually need:\n   - performance comparison plots (different methods on different datasets)\n   - result visualizations (accuracy, F1, loss curves, etc.)\n   - method comparison plots (overall comparison of multiple methods)\n   - dataset distribution plots (if multiple datasets are involved)\n   - visual summaries of important **tables** (e.g., converting a performance table into a bar/line chart)\n\n3. **Ablation sections** usually need:\n   - component ablation plots (effect of removing/adding components)\n   - hyper-parameter sensitivity plots\n   - ablation comparison plots (effect of each configuration)\n\n4. **File naming rules**:\n   - use lowercase letters and underscores\n   - filenames must be descriptive, e.g. \"main_results.png\", \"ablation_study.png\"\n   - avoid Chinese characters or special symbols\n\n5. **Rules for old_string and new_string** (STRICT - both must be non-empty and based on actual LaTeX content):\n   - `old_string`: **MUST NOT be empty**. It must be an actual text span from the input LaTeX snippet near where the figure should be inserted\n     - it can be a full sentence, part of a paragraph, or context around where the figure is referenced\n   - `new_string`: **MUST NOT be empty**. It must be based on `old_string`, with the LaTeX figure code inserted\n\nLevel of detail (very important):\n- The **description** should be as detailed as reasonably possible, mentioning:\n  - what variables/metrics are on each axis,\n  - which methods or configurations are compared,\n  - which datasets or settings are used,\n  - what trends or key conclusions the figure is meant to highlight.\n- The **figure code** in `new_string` should also be detailed:\n  - use an informative `\\caption{...}` that summarizes the main insights,\n  - use a meaningful `\\label{...}` that follows the naming style `fig:<short_name>`.\n\nOutput format and minimal coverage (strict):\n- You must output a single JSON object wrapped in a `json` code block. The number of items in `figures`\n  must cover **all** visualizable elements you find in the snippet (not limited to two). \n- **Important**: Propose diverse figure types based on the data. Do not limit yourself to only bar charts or line plots.\n- Generic example showing figure diversity:\n\n```json\n{\n  \"figures\": [\n    {\n      \"filename\": \"performance_comparison.png\",\n      \"description\": \"A bar chart comparing accuracy and F1 scores across multiple methods (Method A, Method B, Our Method) on three datasets (Dataset X, Y, Z). X-axis: methods, Y-axis: performance metrics. Shows that Our Method outperforms all baselines on every dataset.\",\n      \"old_string\": \"The experimental results are shown as follows. Our method achieves the best performance on all three datasets.\",\n      \"new_string\": \"The experimental results are shown as follows.\\begin{figure}[htbp]\\centering\\includegraphics[width=0.8\\textwidth]{performance_comparison.png}\\caption{Comparison of accuracy and F1 scores of our method and baselines on three datasets A, B, and C. Our method consistently outperforms all baselines on every dataset.}\\label{fig:performance_comparison}\\end{figure} Our method achieves the best performance on all three datasets.\"\n    },\n    ...\n    {\n      \"filename\": \"loss_curves.png\",\n      \"description\": \"A line plot showing training and validation loss curves over epochs. X-axis: training epochs (0-100), Y-axis: loss values. Multiple lines represent different methods, with error bands showing standard deviation across runs. Demonstrates convergence behavior and overfitting patterns.\",\n      \"old_string\": \"The training process shows consistent convergence across all methods.\",\n      \"new_string\": \"The training process shows consistent convergence across all methods.\\begin{figure}[htbp]\\centering\\includegraphics[width=0.8\\textwidth]{loss_curves.png}\\caption{Training and validation loss curves for different methods over 100 epochs. Error bands indicate standard deviation across 5 runs.}\\label{fig:loss_curves}\\end{figure}\"\n    }\n  ]\n}\n```\n\nField definitions (with abstract descriptions):\n- `figures`: an array of all figure objects to be generated\n  - `filename`: string, the figure file name (use `.png` extension). Abstract: A descriptive identifier for the figure file, following naming conventions.\n  - `description`: string, a **detailed** description of what the figure shows. Abstract: A comprehensive textual specification that describes the figure's content, including chart type, axes, data variables, methods/datasets compared, and key insights to highlight.\n  - `old_string`: string, the original LaTeX text span to be replaced (**MUST NOT be empty**, must be actual text from the input LaTeX snippet). Abstract: A contiguous text segment from the input LaTeX that serves as the insertion anchor point for the figure.\n  - `new_string`: string, the replacement text that contains the LaTeX code to insert the figure (**MUST NOT be empty**, must be based on actual LaTeX content). Abstract: The modified LaTeX text that includes the original `old_string` content plus a complete LaTeX figure environment with proper formatting, caption, and label.\n\nImportant constraints:\n- You **must** output valid JSON (double quotes for keys and strings), with no extra comments or explanations.\n- Apart from the `json` code block, you MUST NOT output any other content.\n- **Figure diversity**: When multiple figures are needed, use **different visualization types** (bar charts, line plots, heatmaps, scatter plots, etc.) rather than repeating the same chart type. Match the visualization type to the data characteristics.\n- You should return an empty `figures` array **only if** the snippet truly contains no quantitative results, comparisons, ablations, tables, or figure-worthy content.\n- If the snippet includes any performance numbers, tables (e.g. `\\begin{table}...`), or existing figure environments (e.g. `\\begin{figure}...`), you **must** propose at least one figure in `figures` that visualizes or summarizes these results (even if similar content is already shown in the LaTeX).\n- Each figure must have a unique `filename`.\n- **CRITICAL**: Both `old_string` and `new_string` for each figure **MUST NOT be empty strings**. They must contain actual text from the input LaTeX snippet. If you cannot find suitable text in the input to use as `old_string`, do NOT include that figure in the output."
      },
      {
        "role": "user",
        "content": "[LaTeX 片段]\n\n   1: \\section{Ablation Studies}\n   2: \\subsection{Ablation Study}\n   3: \\label{sec:ablation}\n   4: \n   5: We conduct a comprehensive ablation study on the Kinetics-GEBD validation set to validate the contribution of each component in \\textbf{ESTimator++}. All experiments follow the implementation details in Section~\\ref{sec:setup}.\n   6: \n   7: \\subsubsection{Impact of Proposed Components}\n   8: We start from a baseline model that uses a standard Transformer decoder for prediction and a single reconstruction error with a fixed heuristic threshold for detection. This baseline achieves an average F1 score of 0.715. We then sequentially integrate our proposed components, with results summarized in Table~\\ref{tab:ablation_components}.\n   9: \n  10: \\begin{table}[htbp]\n  11: \\centering\n  12: \\caption{Ablation study on the contribution of each proposed component. Evaluated on Kinetics-GEBD validation set (Average F1). $\\Delta$ denotes the improvement over the previous row.}\n  13: \\label{tab:ablation_components}\n  14: \\begin{tabular}{lcccccc}\n  15: \\toprule\n  16: \\textbf{Variant} & \\textbf{HMT} & \\textbf{SMPE} & \\textbf{SCL} & \\textbf{AMTD} & \\textbf{Avg F1} & $\\Delta$ \\\\\n  17: \\midrule\n  18: Baseline (ESTimator Core) & & & & & 0.715 & -- \\\\\n  19: + Hierarchical Memory (HMT) & \\checkmark & & & & 0.733 & +0.018 \\\\\n  20: + Structured Error (SMPE) & \\checkmark & \\checkmark & & & 0.754 & +0.021 \\\\\n  21: + Consistency Loss (SCL) & \\checkmark & \\checkmark & \\checkmark & & 0.769 & +0.015 \\\\\n  22: + Adaptive Discriminator (AMTD) & \\checkmark & \\checkmark & \\checkmark & \\checkmark & \\textbf{0.778} & \\textbf{+0.029} \\\\\n  23: \\bottomrule\n  24: \\end{tabular}\n  25: \\end{table}\n  26: \n  27: Integrating the \\textbf{Hierarchical Memory-augmented Transformer (HMT)} improves performance by +1.8\\%, demonstrating the importance of maintaining stable event context for consistent prediction. Replacing the single error with the \\textbf{Structured Multi-view Prediction Error (SMPE)} yields a further gain of +2.1\\%, confirming that a composite error signal provides richer boundary cues. Employing the \\textbf{Structural Consistency Loss (SCL)} for training adds another +1.5\\%, validating that enforcing intra-event smoothness and feature clustering shapes more discriminative representations. Finally, substituting the heuristic threshold with the learned \\textbf{Adaptive Multi-scale Temporal Discriminator (AMTD)} provides the most substantial single-module improvement of +2.9\\%, underscoring the advantage of a data-driven decision function. The full model integrating all components achieves the best performance of \\textbf{0.778}, confirming their synergistic effect.\n  28: \n  29: \\subsubsection{Analysis of the Structured Multi-view Prediction Error (SMPE)}\n  30: We analyze the contribution of each error view within the SMPE by ablating them individually from the full model. Results are presented in Table~\\ref{tab:ablation_smpe}. Removing the \\textbf{Predictive Smoothness Error} causes the most significant drop (-1.7\\% in Avg F1), highlighting its sensitivity to event transitions. Omitting the \\textbf{Memory Perturbation Error} leads to a -1.2\\% decrease, demonstrating the importance of tracking high-level event schema changes. Removing the primary \\textbf{Feature Reconstruction Error} also degrades performance (-1.0\\%). Using any single error view consistently underperforms compared to the full SMPE vector, validating our composite design.\n  31: \n  32: \\begin{table}[htbp]\n  33: \\centering\n  34: \\caption{Ablation on the components of the Structured Multi-view Prediction Error (SMPE). Evaluated on Kinetics-GEBD validation set (Average F1).}\n  35: \\label{tab:ablation_smpe}\n  36: \\begin{tabular}{lc}\n  37: \\toprule\n  38: \\textbf{Error Components Used} & \\textbf{Avg F1} \\\\\n  39: \\midrule\n  40: \\textbf{Full SMPE} ($E^{(r)}, E^{(s)}, E^{(m)}$) & \\textbf{0.778} \\\\\n  41: \\hline\n  42: $E^{(s)}, E^{(m)}$ (w/o $E^{(r)}$) & 0.768 \\\\\n  43: $E^{(r)}, E^{(m)}$ (w/o $E^{(s)}$) & 0.761 \\\\\n  44: $E^{(r)}, E^{(s)}$ (w/o $E^{(m)}$) & 0.766 \\\\\n  45: \\hline\n  46: Only $E^{(r)}$ & 0.756 \\\\\n  47: Only $E^{(s)}$ & 0.749 \\\\\n  48: Only $E^{(m)}$ & 0.738 \\\\\n  49: \\bottomrule\n  50: \\end{tabular}\n  51: \\end{table}\n  52: \n  53: \\subsubsection{Design Choices for the Adaptive Discriminator (AMTD)}\n  54: We analyze key design choices in the AMTD module. Results are shown in Table~\\ref{tab:ablation_amtd}. Replacing the AMTD with the original heuristic Online Boundary Detector (OBD) causes a performance drop to 0.748. Using a \\textbf{single-scale} Temporal Convolutional Network (TCN) instead of the multi-scale architecture reduces Avg F1 to 0.771. Removing the \\textbf{self-attention based dynamic fusion} and simply concatenating multi-scale features results in a score of 0.774. These ablations confirm that each aspect of the AMTD's design—its learned nature, multi-scale perception, and adaptive fusion—contributes to its effectiveness.\n  55: \n  56: \\begin{table}[htbp]\n  57: \\centering\n  58: \\caption{Ablation on the design of the Adaptive Multi-scale Temporal Discriminator (AMTD). Evaluated on Kinetics-GEBD validation set (Average F1).}\n  59: \\label{tab:ablation_amtd}\n  60: \\begin{tabular}{lc}\n  61: \\toprule\n  62: \\textbf{AMTD Variant} & \\textbf{Avg F1} \\\\\n  63: \\midrule\n  64: \\textbf{Full AMTD (Ours)} & \\textbf{0.778} \\\\\n  65: \\hline\n  66: Replace with ESTimator's OBD & 0.748 \\\\\n  67: Single-scale TCN (kernel=7) & 0.771 \\\\\n  68: Multi-scale TCN w/o Self-Attention Fusion & 0.774 \\\\\n  69: \\bottomrule\n  70: \\end{tabular}\n  71: \\end{table}\n  72: \n  73: \\subsubsection{Utility of the Structural Consistency Loss (SCL)}\n  74: We dissect the contribution of the two regularization terms in the SCL. As shown in Table~\\ref{tab:ablation_loss}, training with only the \\textbf{Focal Reconstruction Loss} yields a baseline score of 0.754. Adding the \\textbf{Intra-event Smoothness Loss} improves performance to 0.766. Further incorporating the \\textbf{Intra-event Clustering Loss} to form the full SCL pushes the score to 0.769. The full SCL, combining both regularizers, delivers the best result, confirming that jointly optimizing for local accuracy and global temporal coherence is an effective strategy.\n  75: \n  76: \\begin{table}[htbp]\n  77: \\centering\n  78: \\caption{Ablation on the components of the Structural Consistency Loss (SCL). The HMT and SMPE are used in all variants. Evaluated on Kinetics-GEBD validation set (Average F1).}\n  79: \\label{tab:ablation_loss}\n  80: \\begin{tabular}{lc}\n  81: \\toprule\n  82: \\textbf{Training Loss Variant} & \\textbf{Avg F1} \\\\\n  83: \\midrule\n  84: $\\mathcal{L}_{Focal}$ only & 0.754 \\\\\n  85: $\\mathcal{L}_{Focal} + \\mathcal{L}_{Smooth}$ & 0.766 \\\\\n  86: $\\mathcal{L}_{Focal} + \\mathcal{L}_{Cluster}$ & 0.762 \\\\\n  87: \\textbf{Full SCL} ($\\mathcal{L}_{Focal} + \\mathcal{L}_{Smooth} + \\mathcal{L}_{Cluster}$) & \\textbf{0.769} \\\\\n  88: \\bottomrule\n  89: \\end{tabular}\n  90: \\end{table}\n  91: \n  92: \\textbf{Summary.} Our ablation studies provide compelling evidence for the necessity and effectiveness of every component in \\textbf{ESTimator++}. The hierarchical memory (HMT) establishes a robust predictive foundation, the structured error (SMPE) extracts optimal boundary cues, the consistency loss (SCL) shapes the learning objective, and the adaptive discriminator (AMTD) makes precise online decisions. The full model's superior performance arises from their seamless integration.\n\n请根据上述 LaTeX 片段，分析需要绘制哪些图表，并返回 JSON 格式的结果。\n"
      }
    ]
  },
  "response": {
    "raw_response": "```json\n{\n  \"figures\": [\n    {\n      \"filename\": \"ablation_components_line_plot.png\",\n      \"description\": \"A line plot showing the cumulative improvement in Average F1 score as each proposed component is sequentially added to the baseline model. X-axis represents the variants in order: Baseline, +HMT, +SMPE, +SCL, +AMTD. Y-axis shows the Average F1 score (ranging from 0.715 to 0.778). The line connects the points with markers at each variant, and annotations indicate the delta improvements (+0.018, +0.021, +0.015, +0.029). This highlights the synergistic effect of all components, with the full model achieving the highest performance.\",\n      \"old_string\": \"We then sequentially integrate our proposed components, with results summarized in Table~\\\\ref{tab:ablation_components}.\",\n      \"new_string\": \"We then sequentially integrate our proposed components, with results summarized in Table~\\\\ref{tab:ablation_components}.\\\\begin{figure}[htbp]\\\\centering\\\\includegraphics[width=0.8\\\\textwidth]{ablation_components_line_plot.png}\\\\caption{Line plot of Average F1 scores showing progressive improvements from adding each component (HMT, SMPE, SCL, AMTD) to the baseline on the Kinetics-GEBD validation set. The full model achieves the best score of 0.778.}\\\\label{fig:ablation_components}\\\\end{figure}\"\n    },\n    {\n      \"filename\": \"ablation_smpe_bar_chart.png\",\n      \"description\": \"A bar chart comparing the Average F1 scores for different combinations of error components in the Structured Multi-view Prediction Error (SMPE). X-axis lists the variants: Full SMPE, w/o E^{(r)}, w/o E^{(s)}, w/o E^{(m)}, Only E^{(r)}, Only E^{(s)}, Only E^{(m)}. Y-axis shows Average F1 scores (ranging from 0.738 to 0.778). Bars are colored differently for full, ablated, and single-component variants. This illustrates that the full SMPE outperforms all partial or single-error configurations, with the largest drop when removing Predictive Smoothness Error.\",\n      \"old_string\": \"Results are presented in Table~\\\\ref{tab:ablation_smpe}.\",\n      \"new_string\": \"Results are presented in Table~\\\\ref{tab:ablation_smpe}.\\\\begin{figure}[htbp]\\\\centering\\\\includegraphics[width=0.8\\\\textwidth]{ablation_smpe_bar_chart.png}\\\\caption{Bar chart comparing Average F1 scores for ablations of SMPE components on the Kinetics-GEBD validation set. The full SMPE achieves the highest score, validating the composite design.}\\\\label{fig:ablation_smpe}\\\\end{figure}\"\n    },\n    {\n      \"filename\": \"ablation_amtd_scatter_plot.png\",\n      \"description\": \"A scatter plot visualizing the Average F1 scores for variants of the Adaptive Multi-scale Temporal Discriminator (AMTD). X-axis categorically positions the variants: Full AMTD, Replace with OBD, Single-scale TCN, Multi-scale TCN w/o Self-Attention Fusion. Y-axis shows Average F1 scores (ranging from 0.748 to 0.778). Points are marked with different shapes and colors, connected by lines to show performance drops from the full model. This emphasizes the contributions of multi-scale perception and adaptive fusion to the AMTD's effectiveness.\",\n      \"old_string\": \"Results are shown in Table~\\\\ref{tab:ablation_amtd}.\",\n      \"new_string\": \"Results are shown in Table~\\\\ref{tab:ablation_amtd}.\\\\begin{figure}[htbp]\\\\centering\\\\includegraphics[width=0.8\\\\textwidth]{ablation_amtd_scatter_plot.png}\\\\caption{Scatter plot of Average F1 scores for AMTD design variants on the Kinetics-GEBD validation set. The full AMTD outperforms all alternatives, confirming its key design choices.}\\\\label{fig:ablation_amtd}\\\\end{figure}\"\n    },\n    {\n      \"filename\": \"ablation_scl_box_plot.png\",\n      \"description\": \"A box plot (simulated for single values as points with pseudo-distributions for visualization) comparing Average F1 scores for different combinations of the Structural Consistency Loss (SCL) terms. X-axis lists the variants: L_{Focal} only, L_{Focal} + L_{Smooth}, L_{Focal} + L_{Cluster}, Full SCL. Y-axis shows Average F1 scores (ranging from 0.754 to 0.769). Each 'box' represents the score with minimal spread for illustration, highlighting improvements from adding smoothness and clustering losses. This demonstrates that the full SCL provides the best performance by optimizing local and global coherence.\",\n      \"old_string\": \"As shown in Table~\\\\ref{tab:ablation_loss},\",\n      \"new_string\": \"As shown in Table~\\\\ref{tab:ablation_loss},\\\\begin{figure}[htbp]\\\\centering\\\\includegraphics[width=0.8\\\\textwidth]{ablation_scl_box_plot.png}\\\\caption{Box plot of Average F1 scores for SCL component ablations on the Kinetics-GEBD validation set. The full SCL achieves the highest score, showing the benefit of combined regularizers.}\\\\label{fig:ablation_scl}\\\\end{figure}\"\n    }\n  ]\n}\n```",
    "usage": {
      "input_tokens": 4539,
      "output_tokens": 2541
    }
  },
  "parsed_success": true,
  "figures_count": 4
}