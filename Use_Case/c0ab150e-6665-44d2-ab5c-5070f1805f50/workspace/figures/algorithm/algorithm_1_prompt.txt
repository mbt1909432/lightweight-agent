Create an abstract conceptual diagram illustrating the high-level architecture of ESTimator++ for Online Generic Event Boundary Detection, presented as a clean, minimalistic line drawing in a professional academic style suitable for top conferences like NeurIPS or CVPR. This is not a flowchart with decision symbols or process boxes, but an abstract framework diagram emphasizing conceptual modules, logical relationships, and data flows using abstract shapes and connections. Use a horizontal layout from left to right on a white background, with clear visual hierarchy through module grouping and color-coded arrows.

On the left, depict an abstract input module as a simple rectangular block labeled "Input Frame Features (f_t)" in black Arial font, connected by an orange arrow to the central module.

The central module is a large abstract block representing the "Hierarchical Memory-augmented Transformer (HMT)", divided into two sub-modules: an upper rounded rectangle for "Main Event Memory (M_t)" in blue text, and a lower one for "Local Context Cache (C_t)" in blue text. Show abstract internal connections with thin black lines, and an orange arrow looping within for "Gated Update" (labeled in small black text). From HMT, draw a green arrow to an abstract prediction node labeled "Predicted Feature (\hat{f}_t)" in red text.

To the right of HMT, connect with an orange arrow to a module labeled "Structured Multi-view Prediction Error (SMPE)", shown as an abstract triangular shape with three internal compartments labeled "Feature Reconstruction Error (E^r_t)", "Predictive Smoothness Error (E^s_t)", and "Memory Perturbation Error (E^m_t)" in black Arial font. Use orange arrows for input flows into SMPE and a green arrow outputting the concatenated "Error Vector (E_t)".

Further right, connect with a green arrow to the "Adaptive Multi-scale Temporal Discriminator (AMTD)" module, depicted as a layered abstract structure with three parallel bars for "Multi-scale Conv (k1, k2, k3)" in blue text, converging via thin black lines to a fusion node labeled "Self-Attention Fusion" in small black text, then to an output node labeled "Boundary Probability (P_t^{boundary})" in red text.

At the bottom, show an overarching abstract bracket or dashed enclosure spanning the entire diagram, labeled "Structural Consistency Loss (SCL)" in red Arial font, with green arrows indicating feedback loops for training (e.g., from SMPE and AMTD back to HMT).

Use orange arrows for data input and processing flows (e.g., feature streams and updates), green arrows for feedback, output, and prediction paths (e.g., error signals and boundary decisions). Keep text in Arial font, with module names in bold black, variables in blue, and key outputs in red for emphasis. Ensure a simple, uncluttered design with straight lines, no shadows or 3D effects, and balanced spacing for readability in a paper figure.